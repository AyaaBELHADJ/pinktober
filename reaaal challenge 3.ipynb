{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset\n",
    "data= pd.read_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\train.csv\")\n",
    "\n",
    "# Drop irrelevant features\n",
    "data = data.drop(columns=[\"Patient_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Year of Operation</th>\n",
       "      <th>Positive_Axillary_Nodes</th>\n",
       "      <th>Tumor_Size</th>\n",
       "      <th>Radiation_Therapy</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Hormone_Therapy</th>\n",
       "      <th>Survival_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>Married</td>\n",
       "      <td>1962</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>Married</td>\n",
       "      <td>1964</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Married</td>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Married</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Single</td>\n",
       "      <td>1968</td>\n",
       "      <td>5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Marital_Status  Year of Operation  Positive_Axillary_Nodes  Tumor_Size  \\\n",
       "0   77        Married               1962                        5         3.0   \n",
       "1   36        Married               1964                        2         1.9   \n",
       "2   47        Married               1960                        5         2.0   \n",
       "3   54        Married               1965                        0         1.4   \n",
       "4   35         Single               1968                        5         4.1   \n",
       "\n",
       "  Radiation_Therapy Chemotherapy Hormone_Therapy  Survival_Status  \n",
       "0                No          Yes              No                1  \n",
       "1               Yes           No              No                1  \n",
       "2                No           No              No                0  \n",
       "3                No           No              No                0  \n",
       "4               Yes          Yes             Yes                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Marital_Status'] = data['Marital_Status'].map({'Married': 1, 'Single': 0})\n",
    "data['Radiation_Therapy'] = data['Radiation_Therapy'].map({'Yes': 1, 'No': 0})\n",
    "data['Chemotherapy'] = data['Chemotherapy'].map({'Yes': 1, 'No': 0})\n",
    "data['Hormone_Therapy'] = data['Hormone_Therapy'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}\n",
      "Accuracy: 56.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(\"Survival_Status\", axis=1)\n",
    "y = data[\"Survival_Status\"]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = [\"Age\", \"Tumor_Size\", \"Positive_Axillary_Nodes\", \"Year of Operation\"]\n",
    "categorical_features = [\"Marital_Status\", \"Radiation_Therapy\", \"Chemotherapy\", \"Hormone_Therapy\"]\n",
    "\n",
    "# Preprocessing: Standardize numeric features and OneHotEncode categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(drop='first'), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build a KNN model pipeline\n",
    "knn_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11],  # Example values for K\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i used a lot of models but this gave me the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID  Age Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
      "0        1501   62         Single               1966                        4   \n",
      "1        1502   33        Married               1960                        4   \n",
      "2        1503   52        Married               1963                        7   \n",
      "3        1504   56        Married               1968                        7   \n",
      "4        1505   70        Married               1968                        1   \n",
      "\n",
      "   Tumor_Size Radiation_Therapy Chemotherapy Hormone_Therapy  \n",
      "0         1.4               Yes           No              No  \n",
      "1         3.8               Yes           No              No  \n",
      "2         2.1               Yes           No              No  \n",
      "3         1.6               Yes           No              No  \n",
      "4         4.1               Yes           No             Yes  \n"
     ]
    }
   ],
   "source": [
    "# Load the new data file (replace 'new_data.csv' with the actual file path)\n",
    "new_data = pd.read_csv('C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv')\n",
    "\n",
    "# Check the new data to confirm everything is in order\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(columns=[\"Patient_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
      "0   62               0               1966                        4   \n",
      "1   33               1               1960                        4   \n",
      "2   52               1               1963                        7   \n",
      "3   56               1               1968                        7   \n",
      "4   70               1               1968                        1   \n",
      "\n",
      "   Tumor_Size  Radiation_Therapy  Chemotherapy  Hormone_Therapy  \n",
      "0         1.4                  1             0                0  \n",
      "1         3.8                  1             0                0  \n",
      "2         2.1                  1             0                0  \n",
      "3         1.6                  1             0                0  \n",
      "4         4.1                  1             0                1  \n"
     ]
    }
   ],
   "source": [
    "# Map categorical values in the new data\n",
    "new_data = new_data.drop(columns=[\"Patient_ID\"])\n",
    "new_data['Marital_Status'] = new_data['Marital_Status'].map({'Married': 1, 'Single': 0})\n",
    "new_data['Radiation_Therapy'] = new_data['Radiation_Therapy'].map({'Yes': 1, 'No': 0})\n",
    "new_data['Chemotherapy'] = new_data['Chemotherapy'].map({'Yes': 1, 'No': 0})\n",
    "new_data['Hormone_Therapy'] = new_data['Hormone_Therapy'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Verify the mappings\n",
    "print(new_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Year of Operation</th>\n",
       "      <th>Positive_Axillary_Nodes</th>\n",
       "      <th>Tumor_Size</th>\n",
       "      <th>Radiation_Therapy</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Hormone_Therapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1962</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1964</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
       "0   77               1               1962                        5   \n",
       "1   36               1               1964                        2   \n",
       "2   47               1               1960                        5   \n",
       "3   54               1               1965                        0   \n",
       "4   35               0               1968                        5   \n",
       "\n",
       "   Tumor_Size  Radiation_Therapy  Chemotherapy  Hormone_Therapy  \n",
       "0         3.0                  0             1                0  \n",
       "1         1.9                  1             0                0  \n",
       "2         2.0                  0             0                0  \n",
       "3         1.4                  0             0                0  \n",
       "4         4.1                  1             1                1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
      "0     62               0               1966                        4   \n",
      "1     33               1               1960                        4   \n",
      "2     52               1               1963                        7   \n",
      "3     56               1               1968                        7   \n",
      "4     70               1               1968                        1   \n",
      "..   ...             ...                ...                      ...   \n",
      "495   50               0               1967                        4   \n",
      "496   53               1               1961                        3   \n",
      "497   74               1               1963                       11   \n",
      "498   37               0               1960                       23   \n",
      "499   76               1               1969                        7   \n",
      "\n",
      "     Tumor_Size  Radiation_Therapy  Chemotherapy  Hormone_Therapy  \\\n",
      "0           1.4                  1             0                0   \n",
      "1           3.8                  1             0                0   \n",
      "2           2.1                  1             0                0   \n",
      "3           1.6                  1             0                0   \n",
      "4           4.1                  1             0                1   \n",
      "..          ...                ...           ...              ...   \n",
      "495         3.2                  1             0                0   \n",
      "496         3.0                  1             0                0   \n",
      "497         4.1                  1             0                0   \n",
      "498         4.4                  0             0                1   \n",
      "499         3.2                  1             0                0   \n",
      "\n",
      "     Predicted_Survival_Status  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            1  \n",
      "3                            0  \n",
      "4                            1  \n",
      "..                         ...  \n",
      "495                          1  \n",
      "496                          0  \n",
      "497                          1  \n",
      "498                          1  \n",
      "499                          0  \n",
      "\n",
      "[500 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.predict(new_data)\n",
    "\n",
    "# Add predictions to the new DataFrame for clarity (optional)\n",
    "new_data['Predicted_Survival_Status'] = predictions\n",
    "\n",
    "# Display the new DataFrame with predictions\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to CSV file.\n"
     ]
    }
   ],
   "source": [
    "new_data.to_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test predicted.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions added to test.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the existing test CSV file\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\")\n",
    "\n",
    "# Step 2: Ensure that new_data and test_data have the same number of rows\n",
    "# This is important to avoid issues when adding the new column\n",
    "if len(test_data) != len(new_data):\n",
    "    raise ValueError(\"The number of rows in test_data and new_data do not match.\")\n",
    "\n",
    "# Step 3: Add the predictions from new_data as a new column in test_data\n",
    "test_data['Predicted_Survival_Status'] = new_data['Predicted_Survival_Status']\n",
    "\n",
    "# Step 4: Save the updated test DataFrame back to CSV\n",
    "test_data.to_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\", index=False)\n",
    "\n",
    "print(\"Predictions added to test.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped all columns except patientID and predicted survival status.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load the existing test CSV file\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\")\n",
    "\n",
    "# Step 2: Select only the patientID and the predicted survival status columns\n",
    "# Ensure you replace 'Predicted_Survival_Status' with the actual name if it differs\n",
    "filtered_test_data = test_data[['Patient_ID', 'Predicted_Survival_Status']]\n",
    "\n",
    "# Step 3: Save the updated test DataFrame back to CSV\n",
    "filtered_test_data.to_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\", index=False)\n",
    "\n",
    "print(\"Dropped all columns except patientID and predicted survival status.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=1, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=2, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=3, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=4, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=5, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=6, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=7, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=8, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=9, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=10, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=11, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=12, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=13, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=14, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=15, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=16, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=17, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=18, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=uniform; total time=   0.2s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=19, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=uniform; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=uniform; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=distance; total time=   0.1s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=distance; total time=   0.0s\n",
      "[CV] END classifier__n_neighbors=20, classifier__weights=distance; total time=   0.0s\n",
      "Best Parameters: {'classifier__n_neighbors': 1, 'classifier__weights': 'uniform'}\n",
      "Mean CV Accuracy: 55.00%\n",
      "Test Accuracy: 58.67%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE  # Optional for handling class imbalance\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "# Separate features and target\n",
    "X = data.drop(\"Survival_Status\", axis=1)  # Replace with actual target column name\n",
    "y = data[\"Survival_Status\"]\n",
    "\n",
    "# Feature Engineering\n",
    "# Example: Categorizing ages into bins\n",
    "X['Age_Category'] = pd.cut(X['Age'], bins=[0, 30, 60, 90], labels=['Young', 'Middle_Aged', 'Old'])\n",
    "\n",
    "\n",
    "\n",
    "# Adding polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_numeric = X.select_dtypes(include=[np.number])  # Only numeric columns for polynomial features\n",
    "X_poly = poly.fit_transform(X_numeric)\n",
    "\n",
    "# Create a DataFrame for the polynomial features and keep original categorical columns\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(X_numeric.columns))\n",
    "\n",
    "# Concatenate original categorical features with new polynomial features\n",
    "X = pd.concat([X_poly_df, X[['Marital_Status', 'Radiation_Therapy', 'Chemotherapy', 'Hormone_Therapy', 'Age_Category']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove duplicate column names if any\n",
    "X = X.loc[:, ~X.columns.duplicated()]\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = ['Marital_Status', 'Radiation_Therapy', 'Chemotherapy', 'Hormone_Therapy', 'Age_Category']\n",
    "\n",
    "# Preprocessor with imputer and scaler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(drop='first'), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build a model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    \"classifier__n_neighbors\": np.arange(1, 21),  # Try neighbors from 1 to 20\n",
    "    \"classifier__weights\": ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation to get a better estimate of model performance\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5)\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores) * 100:.2f}%\")\n",
    "\n",
    "# Optionally, use SMOTE for oversampling (uncomment if needed)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID  Age Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
      "0        1501   62         Single               1966                        4   \n",
      "1        1502   33        Married               1960                        4   \n",
      "2        1503   52        Married               1963                        7   \n",
      "3        1504   56        Married               1968                        7   \n",
      "4        1505   70        Married               1968                        1   \n",
      "\n",
      "   Tumor_Size Radiation_Therapy Chemotherapy Hormone_Therapy  \n",
      "0         1.4               Yes           No              No  \n",
      "1         3.8               Yes           No              No  \n",
      "2         2.1               Yes           No              No  \n",
      "3         1.6               Yes           No              No  \n",
      "4         4.1               Yes           No             Yes  \n"
     ]
    }
   ],
   "source": [
    "# Load the new data file (replace 'new_data.csv' with the actual file path)\n",
    "new_data = pd.read_csv('C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv')\n",
    "\n",
    "# Check the new data to confirm everything is in order\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Marital_Status  Year of Operation  Positive_Axillary_Nodes  \\\n",
      "0   62               0               1966                        4   \n",
      "1   33               1               1960                        4   \n",
      "2   52               1               1963                        7   \n",
      "3   56               1               1968                        7   \n",
      "4   70               1               1968                        1   \n",
      "\n",
      "   Tumor_Size  Radiation_Therapy  Chemotherapy  Hormone_Therapy  \n",
      "0         1.4                  1             0                0  \n",
      "1         3.8                  1             0                0  \n",
      "2         2.1                  1             0                0  \n",
      "3         1.6                  1             0                0  \n",
      "4         4.1                  1             0                1  \n"
     ]
    }
   ],
   "source": [
    "new_data = new_data.drop(columns=[\"Patient_ID\"])\n",
    "new_data['Marital_Status'] = new_data['Marital_Status'].map({'Married': 1, 'Single': 0})\n",
    "new_data['Radiation_Therapy'] = new_data['Radiation_Therapy'].map({'Yes': 1, 'No': 0})\n",
    "new_data['Chemotherapy'] = new_data['Chemotherapy'].map({'Yes': 1, 'No': 0})\n",
    "new_data['Hormone_Therapy'] = new_data['Hormone_Therapy'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Verify the mappings\n",
    "print(new_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your model and polynomial feature transformer are already trained as 'best_model' and 'poly'\n",
    "# Load new data\n",
    " # Adjust the path as needed\n",
    "\n",
    "# Feature Engineering on new_data\n",
    "new_data['Age_Category'] = pd.cut(new_data['Age'], bins=[0, 30, 60, 90], labels=['Young', 'Middle_Aged', 'Old'])\n",
    "\n",
    "# Create polynomial features for new_data\n",
    "X_new_numeric = new_data.select_dtypes(include=[np.number])  # Only numeric columns for polynomial features\n",
    "X_new_poly = poly.transform(X_new_numeric)  # Use transform instead of fit_transform\n",
    "\n",
    "# Create a DataFrame for the polynomial features\n",
    "X_new_poly_df = pd.DataFrame(X_new_poly, columns=poly.get_feature_names_out(X_new_numeric.columns))\n",
    "\n",
    "# Concatenate with the original categorical features\n",
    "new_data = pd.concat([X_new_poly_df, new_data[['Marital_Status', 'Radiation_Therapy', 'Chemotherapy', 'Hormone_Therapy', 'Age_Category']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Remove duplicate column names if any\n",
    "new_data = new_data.loc[:, ~new_data.columns.duplicated()]\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = best_model.predict(new_data)\n",
    "\n",
    "# Add predictions to new_data\n",
    "new_data['Predicted_Survival_Status'] = predictions\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "new_data.to_csv('path_to_save_predictions.csv', index=False)  # Adjust the path as needed\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions added to test.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the existing test CSV file\n",
    "test_data = pd.read_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\")\n",
    "\n",
    "# Step 2: Ensure that new_data and test_data have the same number of rows\n",
    "# This is important to avoid issues when adding the new column\n",
    "if len(test_data) != len(new_data):\n",
    "    raise ValueError(\"The number of rows in test_data and new_data do not match.\")\n",
    "\n",
    "# Step 3: Add the predictions from new_data as a new column in test_data\n",
    "test_data['Predicted_Survival_Status'] = new_data['Predicted_Survival_Status']\n",
    "\n",
    "# Step 4: Save the updated test DataFrame back to CSV\n",
    "test_data.to_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\", index=False)\n",
    "\n",
    "print(\"Predictions added to test.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped all columns except patientID and predicted survival status.\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\")\n",
    "\n",
    "# Step 2: Select only the patientID and the predicted survival status columns\n",
    "# Ensure you replace 'Predicted_Survival_Status' with the actual name if it differs\n",
    "filtered_test_data = test_data[['Patient_ID', 'Predicted_Survival_Status']]\n",
    "\n",
    "# Step 3: Save the updated test DataFrame back to CSV\n",
    "filtered_test_data.to_csv(\"C:\\\\Users\\\\MASSIVE\\\\Downloads\\\\datathon\\\\test.csv\", index=False)\n",
    "\n",
    "print(\"Dropped all columns except patientID and predicted survival status.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
